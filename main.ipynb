{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f67e01e8-9d70-4a16-b8b3-66b7e56ffa8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wfdb in d:\\anaconda\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: aiohttp>=3.10.11 in d:\\anaconda\\lib\\site-packages (from wfdb) (3.11.18)\n",
      "Requirement already satisfied: fsspec>=2023.10.0 in d:\\anaconda\\lib\\site-packages (from wfdb) (2023.10.0)\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in d:\\anaconda\\lib\\site-packages (from wfdb) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.26.4 in d:\\anaconda\\lib\\site-packages (from wfdb) (1.26.4)\n",
      "Requirement already satisfied: pandas>=2.2.3 in d:\\anaconda\\lib\\site-packages (from wfdb) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.8.1 in d:\\anaconda\\lib\\site-packages (from wfdb) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.13.0 in d:\\anaconda\\lib\\site-packages (from wfdb) (1.15.2)\n",
      "Requirement already satisfied: soundfile>=0.10.0 in d:\\anaconda\\lib\\site-packages (from wfdb) (0.13.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\anaconda\\lib\\site-packages (from aiohttp>=3.10.11->wfdb) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\anaconda\\lib\\site-packages (from aiohttp>=3.10.11->wfdb) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\anaconda\\lib\\site-packages (from aiohttp>=3.10.11->wfdb) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\anaconda\\lib\\site-packages (from aiohttp>=3.10.11->wfdb) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\anaconda\\lib\\site-packages (from aiohttp>=3.10.11->wfdb) (6.0.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\anaconda\\lib\\site-packages (from aiohttp>=3.10.11->wfdb) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\anaconda\\lib\\site-packages (from aiohttp>=3.10.11->wfdb) (1.20.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.2.2->wfdb) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.2.2->wfdb) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.2.2->wfdb) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.2.2->wfdb) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.2.2->wfdb) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.2.2->wfdb) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.2.2->wfdb) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.2.2->wfdb) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\lib\\site-packages (from pandas>=2.2.3->wfdb) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\anaconda\\lib\\site-packages (from pandas>=2.2.3->wfdb) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests>=2.8.1->wfdb) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests>=2.8.1->wfdb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests>=2.8.1->wfdb) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests>=2.8.1->wfdb) (2024.2.2)\n",
      "Requirement already satisfied: cffi>=1.0 in d:\\anaconda\\lib\\site-packages (from soundfile>=0.10.0->wfdb) (1.16.0)\n",
      "Requirement already satisfied: pycparser in d:\\anaconda\\lib\\site-packages (from cffi>=1.0->soundfile>=0.10.0->wfdb) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->wfdb) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wfdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "b136a408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.signal import medfilt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c0c221-d3cc-4263-8a69-d33b0df9ed57",
   "metadata": {},
   "source": [
    "# Extracting and Combining Data by Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3537a7a5-41a3-46ce-a6f2-79413b897c93",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f43c655a-f58d-4e41-9fc7-9e1eea7aa5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the ranges of each stage from their annotation\n",
    "def get_stages(annotation, size):\n",
    "    stages = []\n",
    "    for i, (samp, note) in enumerate(zip(annotation.sample, annotation.aux_note)):\n",
    "        stages.append({\"Label\" : note, \"start\": samp, \"end\": 0}) # dummy end\n",
    "    \n",
    "    for i in range((len(stages) - 1)):\n",
    "        stages[i][\"end\"] = stages[i+1][\"start\"] # each stages end is the next one's beginning\n",
    "    stages[-1][\"end\"] = size # set the end of last stage as the length of the data\n",
    "\n",
    "    return stages  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "e4412628-2f72-4c72-89e4-cbf4b1e7d0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find label of a data point at a given index based on the ranges of each stage\n",
    "def find_label(stages, index):\n",
    "    for stage in stages:\n",
    "        if index >= stage['start'] and index < stage['end']:\n",
    "            return stage[\"Label\"]\n",
    "    return \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "6dc20640-9afa-4d12-bc1c-a99e043a3a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label the AccTempEDA data\n",
    "def extract_labeled_AccTempEDA(record, annotation):\n",
    "    stages = get_stages(annotation, record.p_signal.shape[0]) # get the range for each stage\n",
    "    data = record.p_signal # extract the data into a numpy array\n",
    "    labels = [] # array to store the labels corresponding to each data point in the record\n",
    "    for idx, entry in enumerate(data): # loop over all the data\n",
    "        labels.append((find_label(stages, idx))) # find the label based on the points index\n",
    "    labeled_data = np.column_stack((data, labels)) # append the labels column to the data \n",
    "    return labeled_data # return the labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "a9ec0707-8dc6-487b-a76a-f8b7b58ff552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample by averaging BUT make sure you stay within a given class\n",
    "def downsample_by_averaging(data, factor):\n",
    "    downsampled_data = []\n",
    "    i = 0\n",
    "    while i + factor <= len(data): # cannot use for (range) as we may need to update i\n",
    "        class_label = data[i][-1] # get the expected class lavel\n",
    "        if class_label == data[i + factor - 1][-1]: # if all the data belongs to one class\n",
    "            chunk = data[i: i + factor, :-1].astype(float) # extract a chunk (ignore last column [label] to average and cast to float to counter the upcasting when we added the label)\n",
    "            avg_chunk = np.mean(chunk, axis=0)\n",
    "            downsampled_data.append(np.append(avg_chunk, class_label))  # avg of each column while adding back the label\n",
    "            i += factor\n",
    "        else: # we have crossed into a new class, need to reset i to beginning of the new class\n",
    "            for j in range(i + 1, i + factor):\n",
    "                if data[j-1][-1] != data[j][-1]: # if data at index j has a different class from the one before it, update i and break\n",
    "                    i = j\n",
    "                    break\n",
    "                    \n",
    "    return np.array(downsampled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "33a01bc0-5b4c-4c14-bfaf-1c059177d7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine AccTempEDA and Spo2HR data while truncating them to be of the same length\n",
    "# CRUCIAL but naive assumption! time stamps match after downsampling (technically incorrect)\n",
    "def combine(AccTempEDA, Spo2HR):\n",
    "    min_length = min(len(AccTempEDA), len(Spo2HR)) # finds the minimum length to align the points properly\n",
    "\n",
    "    # concatenate the truncated columns from AccTempEDA with those from Spo2HR and add the labels at the end\n",
    "    combined_data = np.column_stack((AccTempEDA[:min_length, :-1], Spo2HR[:min_length], AccTempEDA[:min_length, -1:]))\n",
    "\n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "bba5071c-119b-47e3-8b20-c0d5764807ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_classes(combined_data):\n",
    "    balanced_data = []\n",
    "    relaxed = False\n",
    "    for data in combined_data:\n",
    "        if data[-1] != \"Relax\": # we've passed the first relax\n",
    "            relaxed = True\n",
    "            balanced_data.append(data)\n",
    "        elif not relaxed:\n",
    "            balanced_data.append(data)\n",
    "    return np.array(balanced_data)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f73be24-0eed-4023-9901-125fd8e1ac42",
   "metadata": {},
   "source": [
    "# Extracting Raw and Preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "0039b668-b876-43da-ab90-04455083d0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val is 1 incase labels are included 0 otherwise \n",
    "def preprocess(wavevec):\n",
    "    final_vec = [] # stores the filtered signals\n",
    "    for i in range(0,len(wavevec[0])): # goes through each point in the signal\n",
    "        one_col = [wavevec[s][i].astype(float) for s in range(0,len(wavevec))] # filters column by column\n",
    "        one_col = medfilt(one_col, kernel_size=9) # filtering each column\n",
    "        if i == 0:\n",
    "            final_vec = one_col\n",
    "        else:\n",
    "            final_vec = np.column_stack((final_vec, one_col))\n",
    "    return final_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "096c06d3-a103-4f51-860b-018043175c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the full data for each subject\n",
    "def get_subject_data_preprocessed(AccTempEDA_record, Spo2HR_record, AccTempEDA_annotation):\n",
    "    AccTempEDA_record.p_signal = preprocess(AccTempEDA_record.p_signal)\n",
    "    AccTempEDA = extract_labeled_AccTempEDA(AccTempEDA_record, AccTempEDA_annotation) # extract and label AccTempEDA record\n",
    "    #print(AccTempEDA[3000])\n",
    "    AccTempEDA = downsample_by_averaging(AccTempEDA, 8) # downsample to match the other Spo2HR's rate\n",
    "    Spo2HR = preprocess(Spo2HR_record.p_signal) # extract Spo2HR record\n",
    "    #print(Spo2HR.shape)\n",
    "    combined_data = combine(AccTempEDA, Spo2HR) # combine both records\n",
    "    #print(len(combined_data))\n",
    "    return combined_data # return the resulting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "296cfbde-f324-4d4b-b04b-6510daf0d64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subject_data_raw(AccTempEDA_record, Spo2HR_record, AccTempEDA_annotation):\n",
    "    AccTempEDA = extract_labeled_AccTempEDA(AccTempEDA_record, AccTempEDA_annotation) # extract and label AccTempEDA record\n",
    "    #print(AccTempEDA[3000])\n",
    "    #print(AccTempEDA)\n",
    "    AccTempEDA = downsample_by_averaging(AccTempEDA, 8) # downsample to match the other Spo2HR's rate\n",
    "    Spo2HR = Spo2HR_record.p_signal # extract Spo2HR record\n",
    "    #print(Spo2HR.shape)\n",
    "    combined_data = combine(AccTempEDA, Spo2HR) # combine both records\n",
    "    #print(len(combined_data))\n",
    "    return combined_data # return the resulting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "666d543f-3311-4171-9aab-11c257a8a9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subject_data_raw_balanced(AccTempEDA_record, Spo2HR_record, AccTempEDA_annotation):\n",
    "    AccTempEDA = extract_labeled_AccTempEDA(AccTempEDA_record, AccTempEDA_annotation) # extract and label AccTempEDA record\n",
    "    #print(AccTempEDA[3000])\n",
    "    #print(AccTempEDA)\n",
    "    AccTempEDA = downsample_by_averaging(AccTempEDA, 8) # downsample to match the other Spo2HR's rate\n",
    "    Spo2HR = Spo2HR_record.p_signal # extract Spo2HR record\n",
    "    #print(Spo2HR.shape)\n",
    "    combined_data = combine(AccTempEDA, Spo2HR) # combine both records\n",
    "    balanced_data = balance_classes(combined_data)\n",
    "    return balanced_data # return the resulting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "330b54fa-98c3-4998-bac5-9f697d005fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the full data for each subject\n",
    "def get_subject_data_preprocessed_balanced(AccTempEDA_record, Spo2HR_record, AccTempEDA_annotation):\n",
    "    AccTempEDA_record.p_signal = preprocess(AccTempEDA_record.p_signal)\n",
    "    AccTempEDA = extract_labeled_AccTempEDA(AccTempEDA_record, AccTempEDA_annotation) # extract and label AccTempEDA record\n",
    "    #print(AccTempEDA[3000])\n",
    "    AccTempEDA = downsample_by_averaging(AccTempEDA, 8) # downsample to match the other Spo2HR's rate\n",
    "    Spo2HR = preprocess(Spo2HR_record.p_signal) # extract Spo2HR record\n",
    "    #print(Spo2HR.shape)\n",
    "    combined_data = combine(AccTempEDA, Spo2HR) # combine both records\n",
    "    balanced_data = balance_classes(combined_data)\n",
    "    return balanced_data # return the resulting data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679a1c61-e23a-4fab-b308-ed091c60f757",
   "metadata": {},
   "source": [
    "# Function to read and get raw data for all subjects and store them in csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "33f91fcb-49f6-4018-a334-83df44c77e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_sub_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2278251-b505-429e-8e58-7c327c8cc6b3",
   "metadata": {},
   "source": [
    "# Function to get the data in the desired window sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "628bdb47-4077-4cf8-8ef3-bac042affb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowSel(data, factor):\n",
    "    # stores the windowed sample\n",
    "    windowed = []\n",
    "    labels = []\n",
    "    # stores the last i in case the window exceeds the size of the sample\n",
    "    for i in range(0, len(data), factor):\n",
    "        # checks if i exceeds the sample size\n",
    "        if i + factor < len(data):\n",
    "            class_label = data[i][-1] # get the expected class lavel\n",
    "            if class_label == data[i + factor - 1][-1]: # if all the data belongs to one class\n",
    "            # adds the windowed sample \n",
    "                windowed.append(data[i: i + factor, :-1])\n",
    "                labels.append(class_label)\n",
    "            else:\n",
    "                continue     \n",
    "    return windowed, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c03a684e-8514-426e-8bfd-1ffc3176882e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[206], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m val \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m20\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m    windowSel(all_sub_info[\u001b[38;5;241m1\u001b[39m],val)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "windowed_samps = []\n",
    "val = 5\n",
    "for i in range(0,20):\n",
    "   windowSel(all_sub_info[1],val)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16556ce-7d9c-4e03-bb12-9a81aa50e7b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cde2bdb-00cc-4108-9362-ee2b515ad049",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de803d9f-7fb7-46cf-9596-41612102713e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf4e9d9-93bd-4a33-b780-d37e7ffdb6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c3137de-d3fc-40c4-80c2-59cd1d85bda1",
   "metadata": {},
   "source": [
    "# Compute Z score [Normalization] (importnat for methods like KNN, logistic regression, SVM and neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a591e6ea-df49-446e-8504-2cf5868c277f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a8fa12-3bc5-409c-bd1c-9b3fb48e61a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "ec08ccde-2963-465d-84d1-810912ea7444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data includes the features without the labels column\n",
    "def normalize_data(train_data, test_data):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(train_data)\n",
    "    X_test_scaled = scaler.transform(test_data)\n",
    "    return X_train_scaled, X_test_scaled\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f9a8db-1fd6-4e9e-b964-ddd04b66c399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f039ebf0-4486-4980-a59e-73c04299c826",
   "metadata": {},
   "source": [
    "# Getting Data Raw, Preprocessed (Balanced and Unbalanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59638ce3-e67a-47d5-b072-906af7a0f9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "872c4574-d9c0-48b1-885f-beb4e06b60a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = rf\"D:\\University\\8.Spring 2025\\Machine\\Project\\non-eeg-dataset-for-assessment-of-neurological-status-1.0.0\\non-eeg-dataset-for-assessment-of-neurological-status-1.0.0\"\n",
    "all_preprocessed_data_balanced=[]\n",
    "all_preprocessed_data=[]\n",
    "all_raw_data_balanced=[]\n",
    "all_raw_data=[]\n",
    "for i in range(1, 21):\n",
    "    AccTempEDA_record = wfdb.rdrecord(fr\"{data_dir}\\Subject{i}_AccTempEDA\")\n",
    "    Spo2HR_record = wfdb.rdrecord(fr\"{data_dir}\\Subject{i}_SpO2HR\")\n",
    "    AccTempEDA_annotation = wfdb.rdann(fr\"{data_dir}\\Subject{i}_AccTempEDA\", 'atr')\n",
    "    \n",
    "    data = get_subject_data_preprocessed(AccTempEDA_record, Spo2HR_record, AccTempEDA_annotation)\n",
    "    raw_data = get_subject_data_raw(AccTempEDA_record, Spo2HR_record, AccTempEDA_annotation)\n",
    "    data_balanced = get_subject_data_preprocessed_balanced(AccTempEDA_record, Spo2HR_record, AccTempEDA_annotation)\n",
    "    raw_data_balanced = get_subject_data_raw_balanced(AccTempEDA_record, Spo2HR_record, AccTempEDA_annotation)\n",
    "    \n",
    "    all_preprocessed_data.append(data)\n",
    "    all_raw_data.append(raw_data)\n",
    "    all_preprocessed_data_balanced.append(data_balanced)\n",
    "    all_raw_data_balanced.append(raw_data_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "5f410096-b5f7-434b-ac99-be1a8e99f946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select windows BUT make sure you stay within a given class\n",
    "def window_data(data, factor):\n",
    "    windowed_data = []\n",
    "    labels = []\n",
    "    i = 0\n",
    "    while i + factor <= len(data): # cannot use for (range) as we may need to update i\n",
    "        class_label = data[i][-1] # get the expected class lavel\n",
    "        if class_label == data[i + factor - 1][-1]: # if all the data belongs to one class\n",
    "            chunk = data[i: i + factor, : -1] # extract a chunk (ignore last column [label] to average and cast to float to counter the upcasting when we added the label)\n",
    "            windowed_data.append(chunk)  # avg of each column while adding back the label\n",
    "            labels.append(class_label)\n",
    "            i += factor\n",
    "        else: # we have crossed into a new class, need to reset i to beginning of the new class\n",
    "            for j in range(i + 1, i + factor):\n",
    "                if data[j-1][-1] != data[j][-1]: # if data at index j has a different class from the one before it, update i and break\n",
    "                    i = j\n",
    "                    break\n",
    "    # flatten the windows\n",
    "\n",
    "    windowed_data = [window.flatten() for window in windowed_data]\n",
    "                    \n",
    "    return np.array(windowed_data).astype(float), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8896e6-9349-43a3-bc61-973446c6efdb",
   "metadata": {},
   "source": [
    "# Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "0aabf8b2-3de9-4b43-8358-1121f43b32b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squared_all_subs(data, norm = False, window = 1):\n",
    "    precision_list_squares = []\n",
    "    recall_list_squares = []\n",
    "    f1_list_squares = []\n",
    "    \n",
    "    for i in range(1, 21):\n",
    "        if(window == 1):\n",
    "            X, y = data[i - 1][:, :-1].astype(float), data[i - 1][:, -1]\n",
    "        else:\n",
    "            X, y = window_data(data[i-1], window)\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        # Prepare lists to store metrics for each fold\n",
    "        all_preds = []\n",
    "        all_true = []\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            if(norm):\n",
    "                X_train, X_test = normalize_data(X_train, X_test)\n",
    "                \n",
    "            clf = RidgeClassifier()\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            \n",
    "            # Collect predictions and true labels\n",
    "            all_preds.extend(y_pred)\n",
    "            all_true.extend(y_test)\n",
    "        \n",
    "        # Final combined classification report\n",
    "        # print(f\"Subject {i}\")\n",
    "        # print(classification_report(all_true, all_preds, zero_division=0))\n",
    "        # print(\"\\n\")\n",
    "    \n",
    "        report_dict = classification_report(all_true, all_preds, output_dict=True, zero_division=0)\n",
    "        macro_avg = report_dict['macro avg']\n",
    "    \n",
    "        avg_precision = macro_avg['precision']\n",
    "        avg_recall = macro_avg['recall']\n",
    "        avg_f1_score = macro_avg['f1-score']\n",
    "    \n",
    "        precision_list_squares.append(avg_precision)\n",
    "        recall_list_squares.append(avg_recall)\n",
    "        f1_list_squares.append(avg_f1_score)\n",
    "        \n",
    "    overall_avg_precision_squares = sum(precision_list_squares) / len(precision_list_squares)\n",
    "    overall_avg_recall_squares = sum(recall_list_squares) / len(recall_list_squares)\n",
    "    overall_avg_f1_squares = sum(f1_list_squares) / len(f1_list_squares)\n",
    "    \n",
    "    print(\"Overall averages for 20 subjects with Least Sqaures classifier:\")\n",
    "    print(f\"Average Precision: {overall_avg_precision_squares:.3f}\")\n",
    "    print(f\"Average Recall: {overall_avg_recall_squares:.3f}\")\n",
    "    print(f\"Average F1-Score: {overall_avg_f1_squares:.3f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096f5028-72fa-48b3-8d1f-9b4c2237b4c0",
   "metadata": {},
   "source": [
    "## Least Squares on Raw Data (Unbalanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "43120efc-07af-4568-98cf-7cb85b0b4d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Least Sqaures classifier:\n",
      "Average Precision: 0.881\n",
      "Average Recall: 0.820\n",
      "Average F1-Score: 0.825\n"
     ]
    }
   ],
   "source": [
    "least_squared_all_subs(all_raw_data, norm = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b877fad8-ca8d-4d41-b4b4-7f801d36dc1c",
   "metadata": {},
   "source": [
    "## Least Squares on Raw Data (Balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "914d31d4-8724-4799-829a-98d15d4f3e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Least Sqaures classifier:\n",
      "Average Precision: 0.943\n",
      "Average Recall: 0.942\n",
      "Average F1-Score: 0.941\n"
     ]
    }
   ],
   "source": [
    "least_squared_all_subs(all_raw_data_balanced, norm = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177086db-5667-4b1c-841a-d6bdc502a75c",
   "metadata": {},
   "source": [
    "## Least Squares on Preprocessed (Unbalanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abc5d27f-77e3-45b9-af7b-97ca9c3ac85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Least Sqaures classifier:\n",
      "Average Precision: 0.836\n",
      "Average Recall: 0.814\n",
      "Average F1-Score: 0.793\n"
     ]
    }
   ],
   "source": [
    "least_squared_all_subs(all_preprocessed_data, norm = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6e4182-c68e-453f-846a-7a3931c3b1c1",
   "metadata": {},
   "source": [
    "## Least Squares on Preprocessed (Balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40a96444-e34f-4364-93a9-c52e48093227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Least Sqaures classifier:\n",
      "Average Precision: 0.931\n",
      "Average Recall: 0.912\n",
      "Average F1-Score: 0.907\n"
     ]
    }
   ],
   "source": [
    "least_squared_all_subs(all_preprocessed_data_balanced, norm = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b03a14-9be6-4a61-b21a-488ed7297859",
   "metadata": {},
   "source": [
    "## Least Squares Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5bed81c9-2630-4eec-801b-511af2ec0294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Least Sqaures classifier:\n",
      "Average Precision: 0.945\n",
      "Average Recall: 0.947\n",
      "Average F1-Score: 0.945\n"
     ]
    }
   ],
   "source": [
    "least_squared_all_subs(all_preprocessed_data_balanced, True, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ede9c126-daf0-4c91-ae40-587dbd23ef93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Least Sqaures classifier:\n",
      "Average Precision: 0.945\n",
      "Average Recall: 0.946\n",
      "Average F1-Score: 0.944\n"
     ]
    }
   ],
   "source": [
    "least_squared_all_subs(all_preprocessed_data_balanced, True, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "909d0acc-c589-4ee3-bd2e-b7195e1d1968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Least Sqaures classifier:\n",
      "Average Precision: 0.945\n",
      "Average Recall: 0.946\n",
      "Average F1-Score: 0.944\n"
     ]
    }
   ],
   "source": [
    "least_squared_all_subs(all_preprocessed_data_balanced, True, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "95f3bd62-d7c8-4109-a2f3-5aab44b0506f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Least Sqaures classifier:\n",
      "Average Precision: 0.938\n",
      "Average Recall: 0.940\n",
      "Average F1-Score: 0.937\n"
     ]
    }
   ],
   "source": [
    "least_squared_all_subs(all_preprocessed_data_balanced, True, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9c1bb3c6-76e6-44be-ba4b-e2694733fd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Least Sqaures classifier:\n",
      "Average Precision: 0.932\n",
      "Average Recall: 0.934\n",
      "Average F1-Score: 0.930\n"
     ]
    }
   ],
   "source": [
    "least_squared_all_subs(all_preprocessed_data_balanced, True, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f5c2675c-f166-46a5-93d1-677173f4119a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Least Sqaures classifier:\n",
      "Average Precision: 0.925\n",
      "Average Recall: 0.924\n",
      "Average F1-Score: 0.922\n"
     ]
    }
   ],
   "source": [
    "least_squared_all_subs(all_preprocessed_data_balanced, True, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8953d5f8-bbce-48a1-b0b0-ad48d32641b3",
   "metadata": {},
   "source": [
    "### interesting observation => as windows grow we actually fall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce5d307-01cd-4f66-a643-69da4f5d58c9",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d6097db7-1136-48e7-9c78-c36454e6bd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_all_subs(data, norm = False, window = 1):\n",
    "    precision_list_squares = []\n",
    "    recall_list_squares = []\n",
    "    f1_list_squares = []\n",
    "    \n",
    "    for i in range(1, 21):\n",
    "        if(window == 1):\n",
    "            X, y = data[i - 1][:, :-1].astype(float), data[i - 1][:, -1]\n",
    "        else:\n",
    "            X, y = window_data(data[i-1], window)\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        # Prepare lists to store metrics for each fold\n",
    "        all_preds = []\n",
    "        all_true = []\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            if(norm):\n",
    "                X_train, X_test = normalize_data(X_train, X_test)\n",
    "                \n",
    "            clf = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            \n",
    "            # Collect predictions and true labels\n",
    "            all_preds.extend(y_pred)\n",
    "            all_true.extend(y_test)\n",
    "    \n",
    "        report_dict = classification_report(all_true, all_preds, output_dict=True, zero_division=0)\n",
    "        macro_avg = report_dict['macro avg']\n",
    "    \n",
    "        avg_precision = macro_avg['precision']\n",
    "        avg_recall = macro_avg['recall']\n",
    "        avg_f1_score = macro_avg['f1-score']\n",
    "    \n",
    "        precision_list_squares.append(avg_precision)\n",
    "        recall_list_squares.append(avg_recall)\n",
    "        f1_list_squares.append(avg_f1_score)\n",
    "        \n",
    "    overall_avg_precision_squares = sum(precision_list_squares) / len(precision_list_squares)\n",
    "    overall_avg_recall_squares = sum(recall_list_squares) / len(recall_list_squares)\n",
    "    overall_avg_f1_squares = sum(f1_list_squares) / len(f1_list_squares)\n",
    "    \n",
    "    print(\"Overall averages for 20 subjects with Logisitic Regression:\")\n",
    "    print(f\"Average Precision: {overall_avg_precision_squares:.3f}\")\n",
    "    print(f\"Average Recall: {overall_avg_recall_squares:.3f}\")\n",
    "    print(f\"Average F1-Score: {overall_avg_f1_squares:.3f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1692634b-6c6e-4d71-afca-710164477743",
   "metadata": {},
   "source": [
    "## doesn't work without normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4426f80f-69d6-4bc6-9cd1-8e3e2be5e250",
   "metadata": {},
   "source": [
    "## Logistic Regression on Preprocessed (Unbalanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b952de6d-4c99-44dd-bd0e-a9154273f36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Logisitic Regression:\n",
      "Average Precision: 0.942\n",
      "Average Recall: 0.933\n",
      "Average F1-Score: 0.936\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_all_subs(all_preprocessed_data, norm = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b664dc0d-99c7-4b60-935b-8aececdb5860",
   "metadata": {},
   "source": [
    "## Logistic Regression on Preprocessed (Balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3859a98f-ca2b-4401-a93d-7e4f14611e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Logisitic Regression:\n",
      "Average Precision: 0.985\n",
      "Average Recall: 0.986\n",
      "Average F1-Score: 0.985\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_all_subs(all_preprocessed_data_balanced, norm = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3f28de-1657-496e-a7f2-f241c398ca40",
   "metadata": {},
   "source": [
    "## Logisitic Regression Windowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9751c00e-0c4a-4ec0-bac6-4e7e5ab72878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Logisitic Regression:\n",
      "Average Precision: 0.984\n",
      "Average Recall: 0.985\n",
      "Average F1-Score: 0.984\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_all_subs(all_preprocessed_data_balanced, True, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "24a32356-5b7c-4912-9daf-51ef98e41723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Logisitic Regression:\n",
      "Average Precision: 0.982\n",
      "Average Recall: 0.983\n",
      "Average F1-Score: 0.982\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_all_subs(all_preprocessed_data_balanced, True, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7ba0fa22-07be-4ed8-b87d-d844c47e4293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Logisitic Regression:\n",
      "Average Precision: 0.980\n",
      "Average Recall: 0.981\n",
      "Average F1-Score: 0.980\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_all_subs(all_preprocessed_data_balanced, True, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8df63ff2-baec-4ac5-b4c9-6afb0923cec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Logisitic Regression:\n",
      "Average Precision: 0.980\n",
      "Average Recall: 0.981\n",
      "Average F1-Score: 0.980\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_all_subs(all_preprocessed_data_balanced, True, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "24a7c3fa-1bb2-4d5f-b2cf-81b8f01fee04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Logisitic Regression:\n",
      "Average Precision: 0.973\n",
      "Average Recall: 0.975\n",
      "Average F1-Score: 0.973\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_all_subs(all_preprocessed_data_balanced, True, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8159425b-f9ed-4cc8-826e-8041ce7c7c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Logisitic Regression:\n",
      "Average Precision: 0.971\n",
      "Average Recall: 0.971\n",
      "Average F1-Score: 0.970\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_all_subs(all_preprocessed_data_balanced, True, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f407a2d5-f8f4-422e-b89c-1f67210f58c1",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "764d05a5-b27c-4933-8938-0324830382d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_all_subs(data, k, norm = False, window = 1):\n",
    "    precision_list_squares = []\n",
    "    recall_list_squares = []\n",
    "    f1_list_squares = []\n",
    "    \n",
    "    for i in range(1, 21):\n",
    "        if(window == 1):\n",
    "            X, y = data[i - 1][:, :-1].astype(float), data[i - 1][:, -1]\n",
    "        else:\n",
    "            X, y = window_data(data[i-1], window)\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        # Prepare lists to store metrics for each fold\n",
    "        all_preds = []\n",
    "        all_true = []\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            if(norm):\n",
    "                X_train, X_test = normalize_data(X_train, X_test)\n",
    "                \n",
    "            clf = SVC(kernel= k, decision_function_shape='ovr')\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            \n",
    "            # Collect predictions and true labels\n",
    "            all_preds.extend(y_pred)\n",
    "            all_true.extend(y_test)\n",
    "        \n",
    "        # Final combined classification report\n",
    "        # print(f\"Subject {i}\")\n",
    "        # print(classification_report(all_true, all_preds, zero_division=0))\n",
    "        # print(\"\\n\")\n",
    "    \n",
    "        report_dict = classification_report(all_true, all_preds, output_dict=True, zero_division=0)\n",
    "        macro_avg = report_dict['macro avg']\n",
    "    \n",
    "        avg_precision = macro_avg['precision']\n",
    "        avg_recall = macro_avg['recall']\n",
    "        avg_f1_score = macro_avg['f1-score']\n",
    "    \n",
    "        precision_list_squares.append(avg_precision)\n",
    "        recall_list_squares.append(avg_recall)\n",
    "        f1_list_squares.append(avg_f1_score)\n",
    "        \n",
    "    overall_avg_precision_squares = sum(precision_list_squares) / len(precision_list_squares)\n",
    "    overall_avg_recall_squares = sum(recall_list_squares) / len(recall_list_squares)\n",
    "    overall_avg_f1_squares = sum(f1_list_squares) / len(f1_list_squares)\n",
    "    \n",
    "    print(f\"Overall averages for 20 subjects with SVM {k}:\")\n",
    "    print(f\"Average Precision: {overall_avg_precision_squares:.3f}\")\n",
    "    print(f\"Average Recall: {overall_avg_recall_squares:.3f}\")\n",
    "    print(f\"Average F1-Score: {overall_avg_f1_squares:.3f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d0d40c-ccda-4a5a-8d8b-57031ee1c745",
   "metadata": {},
   "source": [
    "## Unnormalized also doesn't run (takes too long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cc9123-44f4-47b0-b23e-c52f4e77a4dc",
   "metadata": {},
   "source": [
    "### Linear SVM on Preprocessed (UnBalanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "87048227-1b88-4c88-9c94-91f6f04aa93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with SVM linear:\n",
      "Average Precision: 0.961\n",
      "Average Recall: 0.952\n",
      "Average F1-Score: 0.954\n"
     ]
    }
   ],
   "source": [
    "svm_all_subs(all_preprocessed_data, 'linear', norm = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b238fb3-f3e1-4817-ad9c-4d619fb805a7",
   "metadata": {},
   "source": [
    "### Linear SVM on Preprocessed (Balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "467ff2c7-cfb4-4a1b-b296-a642dc0b3071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with SVM linear:\n",
      "Average Precision: 0.988\n",
      "Average Recall: 0.989\n",
      "Average F1-Score: 0.988\n"
     ]
    }
   ],
   "source": [
    "svm_all_subs(all_preprocessed_data_balanced, 'linear', norm = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53123ee3-3fdd-4e57-a242-c879beaa70a8",
   "metadata": {},
   "source": [
    "### Non-linear SVM on Preprocessed (UnBalanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ce222779-bf76-445b-bf5b-a13ac1d0b97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with SVM rbf:\n",
      "Average Precision: 0.866\n",
      "Average Recall: 0.882\n",
      "Average F1-Score: 0.869\n"
     ]
    }
   ],
   "source": [
    "svm_all_subs(all_preprocessed_data, 'rbf', norm = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd7a860-eed9-4c51-bd73-6dd5891d6208",
   "metadata": {},
   "source": [
    "### Non-linear SVM on Preprocessed (Balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "13eac6eb-9a07-4193-b7eb-0e380ffd43a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with SVM rbf:\n",
      "Average Precision: 0.949\n",
      "Average Recall: 0.950\n",
      "Average F1-Score: 0.948\n"
     ]
    }
   ],
   "source": [
    "svm_all_subs(all_preprocessed_data_balanced, 'rbf', norm = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe268c82-0f79-4a04-95c0-26b110bf4cb1",
   "metadata": {},
   "source": [
    "#### Observation (Linear actually better!!!) since high dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddfda16-ec09-42a5-a9d2-b03b66021ace",
   "metadata": {},
   "source": [
    "### SVM Linear Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aa84bb3d-da72-4bb6-8f7b-b4949ad47b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with SVM linear:\n",
      "Average Precision: 0.987\n",
      "Average Recall: 0.987\n",
      "Average F1-Score: 0.987\n"
     ]
    }
   ],
   "source": [
    "svm_all_subs(all_preprocessed_data_balanced, 'linear', True, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "28db36ea-4f57-4128-b5a2-a53bbfd8b6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with SVM linear:\n",
      "Average Precision: 0.985\n",
      "Average Recall: 0.986\n",
      "Average F1-Score: 0.985\n"
     ]
    }
   ],
   "source": [
    "svm_all_subs(all_preprocessed_data_balanced, 'linear', True, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b8443b09-9a51-4cf0-8a8e-8443589aa03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with SVM linear:\n",
      "Average Precision: 0.981\n",
      "Average Recall: 0.982\n",
      "Average F1-Score: 0.982\n"
     ]
    }
   ],
   "source": [
    "svm_all_subs(all_preprocessed_data_balanced, 'linear', True, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "15ac80bc-a882-4a36-956b-10dc7dec6fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with SVM linear:\n",
      "Average Precision: 0.982\n",
      "Average Recall: 0.983\n",
      "Average F1-Score: 0.982\n"
     ]
    }
   ],
   "source": [
    "svm_all_subs(all_preprocessed_data_balanced, 'linear', True, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "69a68f6c-8c87-426b-8ae4-f7a195cf4356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with SVM linear:\n",
      "Average Precision: 0.973\n",
      "Average Recall: 0.974\n",
      "Average F1-Score: 0.973\n"
     ]
    }
   ],
   "source": [
    "svm_all_subs(all_preprocessed_data_balanced, 'linear', True, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d81cf056-2203-4074-a0b4-c4a0625e515c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with SVM linear:\n",
      "Average Precision: 0.970\n",
      "Average Recall: 0.971\n",
      "Average F1-Score: 0.970\n"
     ]
    }
   ],
   "source": [
    "svm_all_subs(all_preprocessed_data_balanced, 'linear', True, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b88a13-4854-41a4-bef0-ce7051a7c3f4",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9be5fa12-dfb0-4004-9374-c1ed173e5afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_boosting_all_subs(data, norm = False, window = 1):\n",
    "    precision_list_squares = []\n",
    "    recall_list_squares = []\n",
    "    f1_list_squares = []\n",
    "    \n",
    "    for i in range(1, 21):\n",
    "        if(window == 1):\n",
    "            X, y = data[i - 1][:, :-1].astype(float), data[i - 1][:, -1]\n",
    "        else:\n",
    "            X, y = window_data(data[i-1], window)\n",
    "        skf = StratifiedKFold(n_splits=5)\n",
    "        # Prepare lists to store metrics for each fold\n",
    "        all_preds = []\n",
    "        all_true = []\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            if(norm):\n",
    "                X_train, X_test = normalize_data(X_train, X_test)\n",
    "                \n",
    "            clf = GradientBoostingClassifier()\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            \n",
    "            # Collect predictions and true labels\n",
    "            all_preds.extend(y_pred)\n",
    "            all_true.extend(y_test)\n",
    "        \n",
    "        # Final combined classification report\n",
    "        # print(f\"Subject {i}\")\n",
    "        # print(classification_report(all_true, all_preds, zero_division=0))\n",
    "        # print(\"\\n\")\n",
    "    \n",
    "        report_dict = classification_report(all_true, all_preds, output_dict=True, zero_division=0)\n",
    "        macro_avg = report_dict['macro avg']\n",
    "    \n",
    "        avg_precision = macro_avg['precision']\n",
    "        avg_recall = macro_avg['recall']\n",
    "        avg_f1_score = macro_avg['f1-score']\n",
    "    \n",
    "        precision_list_squares.append(avg_precision)\n",
    "        recall_list_squares.append(avg_recall)\n",
    "        f1_list_squares.append(avg_f1_score)\n",
    "        \n",
    "    overall_avg_precision_squares = sum(precision_list_squares) / len(precision_list_squares)\n",
    "    overall_avg_recall_squares = sum(recall_list_squares) / len(recall_list_squares)\n",
    "    overall_avg_f1_squares = sum(f1_list_squares) / len(f1_list_squares)\n",
    "    \n",
    "    print(\"Overall averages for 20 subjects with Gradient Boosting:\")\n",
    "    print(f\"Average Precision: {overall_avg_precision_squares:.3f}\")\n",
    "    print(f\"Average Recall: {overall_avg_recall_squares:.3f}\")\n",
    "    print(f\"Average F1-Score: {overall_avg_f1_squares:.3f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e85be9b4-5710-4a17-bddd-ff5add4d3691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Gradient Boosting:\n",
      "Average Precision: 0.866\n",
      "Average Recall: 0.880\n",
      "Average F1-Score: 0.869\n"
     ]
    }
   ],
   "source": [
    "gradient_boosting_all_subs(all_raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "80618992-4135-4b21-9a58-4496dc9c1ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Gradient Boosting:\n",
      "Average Precision: 0.931\n",
      "Average Recall: 0.922\n",
      "Average F1-Score: 0.924\n"
     ]
    }
   ],
   "source": [
    "gradient_boosting_all_subs(all_raw_data_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2c860018-29bd-4521-98bf-158b15080314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Gradient Boosting:\n",
      "Average Precision: 0.869\n",
      "Average Recall: 0.880\n",
      "Average F1-Score: 0.871\n"
     ]
    }
   ],
   "source": [
    "gradient_boosting_all_subs(all_preprocessed_data, norm = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "81d0f3a5-678b-4b27-a249-4af88ddca5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Gradient Boosting:\n",
      "Average Precision: 0.931\n",
      "Average Recall: 0.922\n",
      "Average F1-Score: 0.923\n"
     ]
    }
   ],
   "source": [
    "gradient_boosting_all_subs(all_preprocessed_data_balanced, norm = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd7f0db-c609-4288-ab7b-c345b00cc674",
   "metadata": {},
   "source": [
    "### Note: no difference with standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cca530-858a-4b39-b184-360abdc93cd3",
   "metadata": {},
   "source": [
    "### Gradient Boosting Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bf00e2ae-a42d-4501-b0e0-f85db012fbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Gradient Boosting:\n",
      "Average Precision: 0.930\n",
      "Average Recall: 0.923\n",
      "Average F1-Score: 0.924\n"
     ]
    }
   ],
   "source": [
    "gradient_boosting_all_subs(all_raw_data_balanced, False, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5493bbc8-dedf-47b8-8b8d-e66f01d435fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Gradient Boosting:\n",
      "Average Precision: 0.929\n",
      "Average Recall: 0.922\n",
      "Average F1-Score: 0.923\n"
     ]
    }
   ],
   "source": [
    "gradient_boosting_all_subs(all_preprocessed_data_balanced, True, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5645b302-02c0-4478-a76c-6b8a5b7a7dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Gradient Boosting:\n",
      "Average Precision: 0.936\n",
      "Average Recall: 0.929\n",
      "Average F1-Score: 0.930\n"
     ]
    }
   ],
   "source": [
    "gradient_boosting_all_subs(all_raw_data_balanced, False, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "da7a3470-7471-4198-b6a4-06d7036c76d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Gradient Boosting:\n",
      "Average Precision: 0.935\n",
      "Average Recall: 0.928\n",
      "Average F1-Score: 0.929\n"
     ]
    }
   ],
   "source": [
    "gradient_boosting_all_subs(all_preprocessed_data_balanced, True, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0579a578-0128-4068-b7fd-bd14c890d776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Gradient Boosting:\n",
      "Average Precision: 0.929\n",
      "Average Recall: 0.923\n",
      "Average F1-Score: 0.924\n"
     ]
    }
   ],
   "source": [
    "gradient_boosting_all_subs(all_raw_data_balanced, False, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d3f1ec79-2ea1-44ac-8755-bbb80d4eb0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Gradient Boosting:\n",
      "Average Precision: 0.931\n",
      "Average Recall: 0.924\n",
      "Average F1-Score: 0.925\n"
     ]
    }
   ],
   "source": [
    "gradient_boosting_all_subs(all_preprocessed_data_balanced, True, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "72bfb44f-e98c-43f1-b8ea-fa7ce38af8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Gradient Boosting:\n",
      "Average Precision: 0.917\n",
      "Average Recall: 0.913\n",
      "Average F1-Score: 0.912\n"
     ]
    }
   ],
   "source": [
    "gradient_boosting_all_subs(all_raw_data_balanced, False, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f8a047da-3e3d-4c64-b436-d25ffaa4cb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Gradient Boosting:\n",
      "Average Precision: 0.918\n",
      "Average Recall: 0.914\n",
      "Average F1-Score: 0.914\n"
     ]
    }
   ],
   "source": [
    "gradient_boosting_all_subs(all_preprocessed_data_balanced, True, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2159267a-d542-4819-b139-9c14a64dbfd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Gradient Boosting:\n",
      "Average Precision: 0.916\n",
      "Average Recall: 0.912\n",
      "Average F1-Score: 0.912\n"
     ]
    }
   ],
   "source": [
    "gradient_boosting_all_subs(all_raw_data_balanced, False, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5ef80800-6741-4a79-97bb-b62d1e31ca1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Gradient Boosting:\n",
      "Average Precision: 0.915\n",
      "Average Recall: 0.911\n",
      "Average F1-Score: 0.911\n"
     ]
    }
   ],
   "source": [
    "gradient_boosting_all_subs(all_preprocessed_data_balanced, True, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ae2d24-30cf-479e-8757-2cd951906001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd8efd6a-cc3a-40f9-bc35-43ffaddca446",
   "metadata": {},
   "source": [
    "## Least Squares leave subject out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "aa8d1860-077d-4a45-ba57-71af11d15f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squared_leave_one_out(data, norm = False, window = 1):\n",
    "    all_preds = []\n",
    "    all_true = []\n",
    "    \n",
    "    for i in range(20):\n",
    "        leave_one_out = np.vstack([data[j] for j in range(20) if j != i])\n",
    "        if(window == 1):    \n",
    "            X_train, y_train = leave_one_out[:, :-1].astype(float), leave_one_out[:, -1]\n",
    "            X_test, y_test = data[i][:, :-1].astype(float), data[i][:, -1]\n",
    "        else:\n",
    "            X_train, y_train = window_data(leave_one_out, window)\n",
    "            X_test, y_test = window_data(data[i], window)\n",
    "\n",
    "        if(norm):\n",
    "            X_train, X_test = normalize_data(X_train, X_test)\n",
    "                \n",
    "        clf = RidgeClassifier(random_state=42)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        all_preds.extend(y_pred)\n",
    "        all_true.extend(y_test)\n",
    "    \n",
    "    report_dict = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "    macro_avg = report_dict['macro avg']\n",
    "    \n",
    "    avg_precision = macro_avg['precision']\n",
    "    avg_recall = macro_avg['recall']\n",
    "    avg_f1_score = macro_avg['f1-score']\n",
    "    \n",
    "    print(\"Overall averages for 20 subjects with Least Sqaures classifier:\")\n",
    "    print(f\"Average Precision: {avg_precision:.3f}\")\n",
    "    print(f\"Average Recall: {avg_recall:.3f}\")\n",
    "    print(f\"Average F1-Score: {avg_f1_score:.3f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "26d61160-ae6c-4a41-b580-3adf729179b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Least Sqaures classifier:\n",
      "Average Precision: 0.604\n",
      "Average Recall: 0.599\n",
      "Average F1-Score: 0.573\n"
     ]
    }
   ],
   "source": [
    "# just checking\n",
    "least_squared_leave_one_out(all_raw_data, norm = False, window = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "fb4de289-3ca9-4841-beb5-0cfcec9ed4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Least Sqaures classifier:\n",
      "Average Precision: 0.866\n",
      "Average Recall: 0.812\n",
      "Average F1-Score: 0.816\n"
     ]
    }
   ],
   "source": [
    "least_squared_leave_one_out(all_preprocessed_data_balanced, norm = True, window = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "17a549e9-aec1-4ce5-8f0a-ce74932008f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (with old aggregation)\n",
    "# least_squared_leave_one_out(all_preprocessed_data_balanced, norm = True, window = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9326e1b6-c776-44f0-b731-b3928b217db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Least Sqaures classifier:\n",
      "Average Precision: 0.875\n",
      "Average Recall: 0.825\n",
      "Average F1-Score: 0.830\n"
     ]
    }
   ],
   "source": [
    "least_squared_leave_one_out(all_preprocessed_data_balanced, norm = True, window = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "9394a978-2203-4230-a721-0edf1ec1c17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Least Sqaures classifier:\n",
      "Average Precision: 0.875\n",
      "Average Recall: 0.827\n",
      "Average F1-Score: 0.831\n"
     ]
    }
   ],
   "source": [
    "least_squared_leave_one_out(all_preprocessed_data_balanced, norm = True, window = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d706186b-cc9c-4830-8fbb-ec72c972e0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Least Sqaures classifier:\n",
      "Average Precision: 0.866\n",
      "Average Recall: 0.820\n",
      "Average F1-Score: 0.825\n"
     ]
    }
   ],
   "source": [
    "least_squared_leave_one_out(all_preprocessed_data_balanced, norm = True, window = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ea76fc08-0f4b-4dae-b747-ab747fc436fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Least Sqaures classifier:\n",
      "Average Precision: 0.851\n",
      "Average Recall: 0.802\n",
      "Average F1-Score: 0.805\n"
     ]
    }
   ],
   "source": [
    "least_squared_leave_one_out(all_preprocessed_data_balanced, norm = True, window = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ab7b7864-da4a-473f-b644-98e3a0ece8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Least Sqaures classifier:\n",
      "Average Precision: 0.831\n",
      "Average Recall: 0.793\n",
      "Average F1-Score: 0.794\n"
     ]
    }
   ],
   "source": [
    "least_squared_leave_one_out(all_preprocessed_data_balanced, norm = True, window = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "b68c43d5-0968-4b11-be1f-69a019b3a091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Least Sqaures classifier:\n",
      "Average Precision: 0.801\n",
      "Average Recall: 0.780\n",
      "Average F1-Score: 0.778\n"
     ]
    }
   ],
   "source": [
    "least_squared_leave_one_out(all_preprocessed_data_balanced, norm = True, window = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c7cb98-79ee-45f1-b601-6f472a98376d",
   "metadata": {},
   "source": [
    "## Logistic regression leave subject out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "4b791bb6-3c88-4f5d-95cd-0e6455a983e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_leave_one_out(data, norm = False, window = 1):\n",
    "    all_preds = []\n",
    "    all_true = []\n",
    "    \n",
    "    for i in range(20):\n",
    "        leave_one_out = np.vstack([data[j] for j in range(20) if j != i])\n",
    "        if(window == 1):    \n",
    "            X_train, y_train = leave_one_out[:, :-1].astype(float), leave_one_out[:, -1]\n",
    "            X_test, y_test = data[i][:, :-1].astype(float), data[i][:, -1]\n",
    "        else:\n",
    "            X_train, y_train = window_data(leave_one_out, window)\n",
    "            X_test, y_test = window_data(data[i], window)\n",
    "\n",
    "        if(norm):\n",
    "            X_train, X_test = normalize_data(X_train, X_test)\n",
    "                \n",
    "        clf = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, random_state = 42)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "        # Collect predictions and true labels\n",
    "        all_preds.extend(y_pred)\n",
    "        all_true.extend(y_test)\n",
    "    \n",
    "    report_dict = classification_report(all_true, all_preds, output_dict=True, zero_division=0)\n",
    "    macro_avg = report_dict['macro avg']\n",
    "    \n",
    "    avg_precision = macro_avg['precision']\n",
    "    avg_recall = macro_avg['recall']\n",
    "    avg_f1_score = macro_avg['f1-score']\n",
    "    \n",
    "    print(\"Overall averages for 20 subjects with Logisitic Regression:\")\n",
    "    print(f\"Average Precision: {avg_precision:.3f}\")\n",
    "    print(f\"Average Recall: {avg_recall:.3f}\")\n",
    "    print(f\"Average F1-Score: {avg_f1_score:.3f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ddcd2c87-7aec-4c0e-afeb-9db5b5e47b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Logisitic Regression:\n",
      "Average Precision: 0.985\n",
      "Average Recall: 0.986\n",
      "Average F1-Score: 0.985\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_all_subs(all_preprocessed_data_balanced, norm = True, window = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1f0ec886-b9d6-4547-afa9-8a0f1e095c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Logisitic Regression:\n",
      "Average Precision: 0.613\n",
      "Average Recall: 0.573\n",
      "Average F1-Score: 0.583\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_leave_one_out(all_preprocessed_data, norm = True, window = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "5be39b52-7724-4da3-a72b-6455da6da8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Logisitic Regression:\n",
      "Average Precision: 0.700\n",
      "Average Recall: 0.700\n",
      "Average F1-Score: 0.700\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_leave_one_out(all_preprocessed_data_balanced, norm = True, window = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "1f9ea738-f531-4110-b051-566508f5a486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Logisitic Regression:\n",
      "Average Precision: 0.702\n",
      "Average Recall: 0.702\n",
      "Average F1-Score: 0.702\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_leave_one_out(all_preprocessed_data_balanced, norm = True, window = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "5a6a98af-9460-466d-9f2e-068aad666396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Logisitic Regression:\n",
      "Average Precision: 0.703\n",
      "Average Recall: 0.703\n",
      "Average F1-Score: 0.703\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_leave_one_out(all_preprocessed_data_balanced, norm = True, window = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "2e322015-e6cf-4653-af99-05e4047506a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Logisitic Regression:\n",
      "Average Precision: 0.701\n",
      "Average Recall: 0.701\n",
      "Average F1-Score: 0.701\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_leave_one_out(all_preprocessed_data_balanced, norm = True, window = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9f10ff9d-0a9f-4ac6-b64f-1c9eecee86ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Logisitic Regression:\n",
      "Average Precision: 0.700\n",
      "Average Recall: 0.701\n",
      "Average F1-Score: 0.700\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_leave_one_out(all_preprocessed_data_balanced, norm = True, window = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "db106ede-13f7-43af-8ca3-7ad29da017a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Logisitic Regression:\n",
      "Average Precision: 0.710\n",
      "Average Recall: 0.712\n",
      "Average F1-Score: 0.711\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_leave_one_out(all_preprocessed_data_balanced, norm = True, window = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d6de3348-362a-41a9-945f-9d0779750cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall averages for 20 subjects with Logisitic Regression:\n",
      "Average Precision: 0.713\n",
      "Average Recall: 0.716\n",
      "Average F1-Score: 0.714\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_leave_one_out(all_preprocessed_data_balanced, norm = True, window = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e592103-e47a-4dd0-aea6-d825cd69c3a5",
   "metadata": {},
   "source": [
    "## SVM Leave one out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "660820cf-44e1-4821-92df-5db49ca67e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_leave_one_out(data, norm = False, window = 1):\n",
    "    all_preds = []\n",
    "    all_true = []\n",
    "    \n",
    "    for i in range(20):\n",
    "        leave_one_out = np.vstack([data[j] for j in range(20) if j != i])\n",
    "        if(window == 1):    \n",
    "            X_train, y_train = leave_one_out[:, :-1].astype(float), leave_one_out[:, -1]\n",
    "            X_test, y_test = data[i][:, :-1].astype(float), data[i][:, -1]\n",
    "        else:\n",
    "            X_train, y_train = window_data(leave_one_out, window)\n",
    "            X_test, y_test = window_data(data[i], window)\n",
    "\n",
    "        if(norm):\n",
    "            X_train, X_test = normalize_data(X_train, X_test)\n",
    "                \n",
    "        clf = LinearSVC(random_state=42, max_iter=10000) \n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "            \n",
    "        # Collect predictions and true labels\n",
    "        all_preds.extend(y_pred)\n",
    "        all_true.extend(y_test)\n",
    "        \n",
    "    \n",
    "    report_dict = classification_report(all_true, all_preds, output_dict=True, zero_division=0)\n",
    "    macro_avg = report_dict['macro avg']\n",
    "    \n",
    "    avg_precision = macro_avg['precision']\n",
    "    avg_recall = macro_avg['recall']\n",
    "    avg_f1_score = macro_avg['f1-score']\n",
    "    \n",
    "    print(f\"Overall averages for 20 subjects with SVM {k}:\")\n",
    "    print(f\"Average Precision: {avg_precision:.3f}\")\n",
    "    print(f\"Average Recall: {avg_recall:.3f}\")\n",
    "    print(f\"Average F1-Score: {avg_f1_score:.3f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0207f523-db26-4a44-a477-962f44855e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_leave_one_out(all_preprocessed_data, 'linear', norm = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f67ef0e-bf41-478d-abb1-20d23ef7a07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_leave_one_out(all_preprocessed_data_balanced, norm = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476d7816-8af5-4e14-848a-cde518ab343a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2801861b-3866-4556-a03d-6daabae86e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43548"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_raw_data[0])*19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "cc3a48a5-1aad-4879-8c65-c1662ed67054",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = all_raw_data\n",
    "for i in range(1, 21):\n",
    "    new_data = np.vstack([data[j] for j in range(20) if j != i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "cd64522e-a387-4942-8bff-48350790a28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46089"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4299594a-756c-496d-b8ab-164c92ccc961",
   "metadata": {},
   "source": [
    "## Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1df9b70a-248a-4e04-8501-29a36a9ca473",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "96300f90-fc84-49de-b7cc-3684606cab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_distribution_all_subs(data):\n",
    "    for i in range(1, 21):\n",
    "        y = data[i - 1][:, -1]  # Assuming labels are in the last column\n",
    "        class_counts = Counter(y)\n",
    "        print(f\"Subject {i} class distribution:\")\n",
    "        for cls, count in sorted(class_counts.items()):\n",
    "            print(f\"  Class {cls}: {count} instances\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ae2f016c-e4c1-4190-b4d1-3721569714d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 1 class distribution:\n",
      "  Class CognitiveStress: 364 instances\n",
      "  Class EmotionalStress: 400 instances\n",
      "  Class PhysicalStress: 328 instances\n",
      "  Class Relax: 300 instances\n",
      "\n",
      "Subject 2 class distribution:\n",
      "  Class CognitiveStress: 355 instances\n",
      "  Class EmotionalStress: 408 instances\n",
      "  Class PhysicalStress: 327 instances\n",
      "  Class Relax: 300 instances\n",
      "\n",
      "Subject 3 class distribution:\n",
      "  Class CognitiveStress: 354 instances\n",
      "  Class EmotionalStress: 403 instances\n",
      "  Class PhysicalStress: 324 instances\n",
      "  Class Relax: 300 instances\n",
      "\n",
      "Subject 4 class distribution:\n",
      "  Class CognitiveStress: 355 instances\n",
      "  Class EmotionalStress: 399 instances\n",
      "  Class PhysicalStress: 327 instances\n",
      "  Class Relax: 300 instances\n",
      "\n",
      "Subject 5 class distribution:\n",
      "  Class CognitiveStress: 354 instances\n",
      "  Class EmotionalStress: 400 instances\n",
      "  Class PhysicalStress: 326 instances\n",
      "  Class Relax: 300 instances\n",
      "\n",
      "Subject 6 class distribution:\n",
      "  Class CognitiveStress: 356 instances\n",
      "  Class EmotionalStress: 399 instances\n",
      "  Class PhysicalStress: 326 instances\n",
      "  Class Relax: 300 instances\n",
      "\n",
      "Subject 7 class distribution:\n",
      "  Class CognitiveStress: 346 instances\n",
      "  Class EmotionalStress: 399 instances\n",
      "  Class PhysicalStress: 326 instances\n",
      "  Class Relax: 300 instances\n",
      "\n",
      "Subject 8 class distribution:\n",
      "  Class CognitiveStress: 354 instances\n",
      "  Class EmotionalStress: 400 instances\n",
      "  Class PhysicalStress: 327 instances\n",
      "  Class Relax: 300 instances\n",
      "\n",
      "Subject 9 class distribution:\n",
      "  Class CognitiveStress: 354 instances\n",
      "  Class EmotionalStress: 399 instances\n",
      "  Class PhysicalStress: 327 instances\n",
      "  Class Relax: 300 instances\n",
      "\n",
      "Subject 10 class distribution:\n",
      "  Class CognitiveStress: 355 instances\n",
      "  Class EmotionalStress: 398 instances\n",
      "  Class PhysicalStress: 326 instances\n",
      "  Class Relax: 300 instances\n",
      "\n",
      "Subject 11 class distribution:\n",
      "  Class CognitiveStress: 355 instances\n",
      "  Class EmotionalStress: 650 instances\n",
      "  Class PhysicalStress: 327 instances\n",
      "  Class Relax: 300 instances\n",
      "\n",
      "Subject 12 class distribution:\n",
      "  Class CognitiveStress: 354 instances\n",
      "  Class EmotionalStress: 399 instances\n",
      "  Class PhysicalStress: 326 instances\n",
      "  Class Relax: 298 instances\n",
      "\n",
      "Subject 13 class distribution:\n",
      "  Class CognitiveStress: 354 instances\n",
      "  Class EmotionalStress: 399 instances\n",
      "  Class PhysicalStress: 327 instances\n",
      "  Class Relax: 300 instances\n",
      "\n",
      "Subject 14 class distribution:\n",
      "  Class CognitiveStress: 354 instances\n",
      "  Class EmotionalStress: 398 instances\n",
      "  Class PhysicalStress: 326 instances\n",
      "  Class Relax: 300 instances\n",
      "\n",
      "Subject 15 class distribution:\n",
      "  Class CognitiveStress: 354 instances\n",
      "  Class EmotionalStress: 395 instances\n",
      "  Class PhysicalStress: 324 instances\n",
      "  Class Relax: 300 instances\n",
      "\n",
      "Subject 16 class distribution:\n",
      "  Class CognitiveStress: 354 instances\n",
      "  Class EmotionalStress: 399 instances\n",
      "  Class PhysicalStress: 326 instances\n",
      "  Class Relax: 300 instances\n",
      "\n",
      "Subject 17 class distribution:\n",
      "  Class CognitiveStress: 356 instances\n",
      "  Class EmotionalStress: 399 instances\n",
      "  Class PhysicalStress: 326 instances\n",
      "  Class Relax: 303 instances\n",
      "\n",
      "Subject 18 class distribution:\n",
      "  Class CognitiveStress: 354 instances\n",
      "  Class EmotionalStress: 399 instances\n",
      "  Class PhysicalStress: 328 instances\n",
      "  Class Relax: 300 instances\n",
      "\n",
      "Subject 19 class distribution:\n",
      "  Class CognitiveStress: 354 instances\n",
      "  Class EmotionalStress: 399 instances\n",
      "  Class PhysicalStress: 324 instances\n",
      "  Class Relax: 300 instances\n",
      "\n",
      "Subject 20 class distribution:\n",
      "  Class CognitiveStress: 355 instances\n",
      "  Class EmotionalStress: 641 instances\n",
      "  Class PhysicalStress: 327 instances\n",
      "  Class Relax: 298 instances\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_distribution_all_subs(all_raw_data_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca154649-cdc8-459e-81c1-cb10f69e0aae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
